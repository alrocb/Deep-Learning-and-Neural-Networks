{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkaratzas/DL2022-23/blob/main/Problems%202%20-%20Using%20Autograd%20and%20PyTorch/P2_2_Intro_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCQfVywqeefm"
      },
      "source": [
        "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/dkaratzas/DL2022-23/blob/main/Problems%202%20-%20Using%20Autograd%20and%20PyTorch/P2_2_Intro_Tensors.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IF4i31_7jbg"
      },
      "source": [
        "# What is PyTorch?\n",
        "\n",
        "<a href=\"https://pytorch.org/\">Pytorch</a> is a Python based scientific computing package targeted at two types of audience:\n",
        "\n",
        "-  At the low level, it is a tensor library capable to exploit the computational power of GPUs\n",
        "-  At the high level, it is a deep learning research platform that provides maximum flexibility and speed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ng2mpMYgkpu"
      },
      "source": [
        "## Import the library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzX92S587jbm"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y62dQH467jbn"
      },
      "source": [
        "## Getting help in Jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EnKcpjDeefv"
      },
      "source": [
        "The fastest way to get some quick help on something using Jupyter is to just ask! Type any Python object name you want followed by a question mark `?` and the code documentation will be loaded in your notebook. Try it with `torch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxK6Sh1_eefw"
      },
      "outputs": [],
      "source": [
        "torch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jp0ULZceefz"
      },
      "source": [
        "The following command will list all objects of torch that with a name that finishes with \"Tensor\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIqY0-QT7jbo"
      },
      "outputs": [],
      "source": [
        "# In Colab, you can press <esc> to get out of help\n",
        "torch.*Tensor?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmXUgeQreef2"
      },
      "source": [
        "If you use Colab, you also have a handy autocomplete feature at hand. For example, start writing a function name, like `torch.sqrt` if you pause after the first few characters a context menu with possible options will appear. Select the term you meant and press Tab or Enter to autocomplete. Note, this will not work in Jupyter Lab / Notebook out of the box, you would need to install an extension to enable this functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4g-D23eg7jbn"
      },
      "outputs": [],
      "source": [
        "# start typing torch.sqr...  wait and then use <Tab> or <Enter> to autocomplete to torch.sqrt()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfZb4m1Heef4"
      },
      "source": [
        "In Jupyter Lab (but not in CoLab) you can access the documentation by clicking on the Python object and pressing `<Shift>` + `<Tab>`. Try it in the line below (if you are using Jupyter Lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED3Z0RKO7jbo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1475fe16-802d-404d-97f8-bc0b2250573e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Module()"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ],
      "source": [
        "torch.nn.Module()  # <Shift>+<Tab>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSeh3eqUeef6"
      },
      "source": [
        "You should see the same result as with the line below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrBufY4q7jbo"
      },
      "outputs": [],
      "source": [
        "# Annotate your functions / classes!\n",
        "torch.nn.Module?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T2iX7CKeef7"
      },
      "source": [
        "Where does this documentation come from? Part of it comes from the code itself, and part of it from the annotations (special comments) that are introduced in the function / class definitions. To have a look at the actual code of a function, just use a double `??`. See for example below, and get used to annotating your functions / classes as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6gVzBNi7jbp"
      },
      "outputs": [],
      "source": [
        "torch.nn.Module??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3odUxKDa7jbq"
      },
      "source": [
        "## Torch!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBnGvPWReef9"
      },
      "source": [
        "At the core of PyTorch there is the `Tensor` class. It is very much like numpy's arrays, but supports autograd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxMMJ1tO7jbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be85f3f-98d6-432d-d87c-ca92b0cb981b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ],
      "source": [
        "# Generate a tensor of size 2x3x4\n",
        "t = torch.Tensor(2, 3, 4)\n",
        "type(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3xcTvfc7jbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f1852d-f444-462e-b061-8d6b98070256"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ],
      "source": [
        "# Get the size of the tensor\n",
        "t.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXAmpH-Z7jbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d033d0-f1d8-42ef-edc1-1a56a25bfa5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "point in a 24 dimensional space\n",
            "organised in 3 sub-dimensions\n"
          ]
        }
      ],
      "source": [
        "# prints dimensional space and sub-dimensions\n",
        "print(f'point in a {t.numel()} dimensional space')\n",
        "print(f'organised in {t.dim()} sub-dimensions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC8XADcV7jbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70b5184-0fc2-4b4c-8e0a-be6c0cea4f97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-8.8016e-35,  4.5860e-41,  4.7295e+03,  0.0000e+00],\n",
              "         [ 3.3631e-44,  0.0000e+00,  1.1210e-44,  0.0000e+00],\n",
              "         [ 6.7262e-44,  0.0000e+00,  1.1210e-43,  0.0000e+00]],\n",
              "\n",
              "        [[ 4.9292e+03,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
              "         [ 0.0000e+00,  1.8750e+00,  0.0000e+00,  0.0000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ARC3wOQ7jbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2659446-f6f4-4fa4-902e-2326cb40c47f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 3., 2., 6.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 5., 1., 5.]],\n",
              "\n",
              "        [[4., 7., 2., 3.],\n",
              "         [6., 6., 9., 4.],\n",
              "         [4., 3., 2., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ],
      "source": [
        "# Mind the underscore!\n",
        "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
        "# For example: x.copy_(y), x.t_(), x.random_(n) will change x.\n",
        "t.random_(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL2ajaMg7jbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725a5034-01e6-44a7-abeb-43aa60908f76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 3., 2., 6., 0., 0., 0., 0.],\n",
              "        [0., 5., 1., 5., 4., 7., 2., 3.],\n",
              "        [6., 6., 9., 4., 4., 3., 2., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "r = t.view(3, 8)\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivViPVSG7jbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707ad2fb-bfb8-4004-f456-cdb7afe5e8c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ],
      "source": [
        "# As you can see zero_ would replace r with 0's which was originally filled with integers\n",
        "r.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7KuYVw17jbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dedd708-5cc8-4d7a-d705-158d257ff46e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIhTq4nIdqx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1831b61-9f4c-4946-9b19-d7953e1ea79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 4, 1) (8, 1)\n",
            "torch.Size([2, 3, 4]) torch.Size([3, 8])\n"
          ]
        }
      ],
      "source": [
        "# What are strides. And how are they related to shapes?\n",
        "print(t.stride(), r.stride())\n",
        "print(t.shape, r.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uum4hxYkffli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1270c2a-8342-44fb-c4fa-7fe8e6240ab4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[8., 1., 9., 3.],\n",
              "         [3., 5., 6., 9.],\n",
              "         [3., 2., 3., 7.]],\n",
              "\n",
              "        [[4., 6., 5., 9.],\n",
              "         [5., 1., 4., 3.],\n",
              "         [3., 1., 9., 4.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ],
      "source": [
        "# Let's try that again without doing the operations in place\n",
        "t.random_(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJM4es_M-p2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071cf07c-26bf-40ab-9c8f-ad05413dd026"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ],
      "source": [
        "# Not in place\n",
        "r = t.view(3, 8)\n",
        "r = torch.zeros_like(r)\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivw8wI5U-12D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a112de-9d7d-4850-ed33-5511c7ed090b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[8., 1., 9., 3.],\n",
              "         [3., 5., 6., 9.],\n",
              "         [3., 2., 3., 7.]],\n",
              "\n",
              "        [[4., 6., 5., 9.],\n",
              "         [5., 1., 4., 3.],\n",
              "         [3., 1., 9., 4.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJdGqvwTdiMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53713517-c4a6-4fe8-e713-254a9a0701d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 4, 1) (8, 1)\n"
          ]
        }
      ],
      "source": [
        "# What are strides?\n",
        "print(t.stride(), r.stride())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Fcui7u7jbs"
      },
      "outputs": [],
      "source": [
        "# This *is* important\n",
        "s = r.clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rm9a0zci7jbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c2a222-0182-402a-9824-9f986feda866"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "# In-place fill of 1's\n",
        "s.fill_(1)\n",
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1K3hywm7jbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5861b062-309d-46a7-f2a9-e7d48b6a92e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ],
      "source": [
        "# Because we cloned r, even though we did an in-place operation, this doesn't affect r\n",
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir1URH3v7jbt"
      },
      "source": [
        "## Vectors (1D Tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRCvA1R17jbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2de442-12f9-4976-ec73-c3572112bb10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ],
      "source": [
        "# Creates a 1D tensor of integers 1 to 4\n",
        "v = torch.Tensor([1, 2, 3, 4])\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmkSLrIi7jbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6184ed-782a-4c34-d56f-2a96714d5f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dim: 1, size: 4\n"
          ]
        }
      ],
      "source": [
        "# Print number of dimensions (1D) and size of tensor\n",
        "print(f'dim: {v.dim()}, size: {v.size()[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K03oi68R7jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26dec67b-a6d0-495d-d3dc-6b097d870a09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 2., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ],
      "source": [
        "w = torch.Tensor([1, 0, 2, 0])\n",
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGGpVC_b7jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e404efa-eccd-46ed-fd73-ae7d8ce623d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 6., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ],
      "source": [
        "# Element-wise multiplication\n",
        "v * w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq7-Aqs_7jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50da9b9a-07c8-44cb-b233-c1a5cc868d0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ],
      "source": [
        "# Scalar product: 1*1 + 2*0 + 3*2 + 4*0\n",
        "v @ w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-oXbFTO7jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d501a8-c935-474c-e440-25ac50d63226"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9., 8., 5., 7., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ],
      "source": [
        "# In-place replacement of random number from 0 to 10\n",
        "x = torch.Tensor(5).random_(10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00BUa-L47jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234ddc49-1003-4f49-f8b2-4dad91db16c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first: 9.0, last: 3.0\n"
          ]
        }
      ],
      "source": [
        "print(f'first: {x[0]}, last: {x[-1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX_Uy_T17jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786f9a1c-64ce-4469-c2dd-cf4b6fd36db8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ],
      "source": [
        "# Extract sub-Tensor [from:to)\n",
        "x[1:2 + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPNJt5Kt7jbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eccbccd-f5b0-4313-d2bf-5894c56d3283"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ],
      "source": [
        "# Create a tensor with integers ranging from 1 to 4 (both included)\n",
        "v = torch.arange(1, 5)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_nwZPg-7jbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf8d3c4-a2e9-45c8-908e-787319eded5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  4,  9, 16]) tensor([1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Square all elements in the tensor\n",
        "print(v.pow(2), v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De7wobZv7jbv"
      },
      "source": [
        "## Matrices (2D Tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuiyP0MK7jbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade79ec7-d1ef-438c-cdcc-c0959806968b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ],
      "source": [
        "# Create a 2x4 tensor\n",
        "m = torch.Tensor([[2, 5, 3, 7],\n",
        "                  [4, 2, 1, 9]])\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI36U8sv7jbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ed8173-e649-4e82-d513-f279d352aefb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ],
      "source": [
        "m.dim()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f91z4dw7jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644a1442-a555-4941-fa06-3b0cae41ac85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 -- 4 -- torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "print(m.size(0), m.size(1), m.size(), sep=' -- ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vuLnT2z7jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa17606-1cb7-4334-bbd5-98431ff33c15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ],
      "source": [
        "# Indexing row 0, column 2 (0-indexed)\n",
        "m[0][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLIC7pG97jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98b85f90-291f-4b48-c154-97a06fd96921"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ],
      "source": [
        "# Indexing row 0, column 2 (0-indexed)\n",
        "m[0, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsutF_zc7jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18ac465-a642-4022-934b-70d6fddc0a41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ],
      "source": [
        "# Indexing column 1, all rows (returns size 2)\n",
        "m[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLg24cHx7jbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815e3499-5b97-49b6-fd65-029d29e6a18f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.],\n",
              "        [2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ],
      "source": [
        "# Indexing column 1, all rows (returns size 2x1)\n",
        "m[:, [1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8nu79EU7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c34ed7-dbe2-41bd-86f3-a6a35911fc3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ],
      "source": [
        "# Indexes row 0, all columns (returns 1x4)\n",
        "m[[0], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYVpTC7l7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd4d57b-7571-4adf-cadb-8ebc39833288"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ],
      "source": [
        "# Create tensor of numbers from 1 to 5)\n",
        "v = torch.arange(1., 5)\n",
        "v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UQd3S3w7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a27694b-fa2b-437d-d308-f05bbf98529f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c10o4XUQ7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b0e779-c742-40b5-c760-e68167b4bb91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([49., 47.])"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ],
      "source": [
        "# Scalar product\n",
        "m @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEkCtsZG7jbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61689de-edec-4808-91a4-a449ecbeab19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(49.)"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ],
      "source": [
        "# Calculated by 1*2 + 2*5 + 3*3 + 4*7\n",
        "m[0, :] @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzxKEjus7jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc0cb4a-1ca5-4887-ecf2-d90b7d5d1a77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([47.])"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ],
      "source": [
        "# Calculated by \n",
        "m[[1], :] @ v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP7c5qI17jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b4c783-a799-44a3-de9c-d14f8fcb8cc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.9551, 5.3596, 3.0912, 7.3721],\n",
              "        [4.4392, 2.1881, 1.7959, 9.6162]])"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ],
      "source": [
        "# Add a random tensor of size 2x4 to m\n",
        "m + torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nli9YIb17jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36926b6c-9673-4281-d8c1-0c93eece0661"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5080, 4.4137, 2.9470, 6.1240],\n",
              "        [3.3132, 1.0018, 0.5884, 8.5819]])"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ],
      "source": [
        "# Subtract a random tensor of size 2x4 to m\n",
        "m - torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0QPbbr87jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce35b204-9a60-4c24-d883-fd60e4828fc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3138, 0.5419, 2.5373, 1.9958],\n",
              "        [3.5355, 0.2385, 0.2463, 4.2517]])"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ],
      "source": [
        "# Multiply a random tensor of size 2x4 to m\n",
        "m * torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRxwhq3p7jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819d7dd2-6961-44ba-a1cf-c20deb78e802"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.5649, 10.2021,  4.4604, 19.1765],\n",
              "        [ 5.3714,  2.1053, 35.3839, 10.8625]])"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ],
      "source": [
        "# Divide m by a random tensor of size 2x4\n",
        "m / torch.rand(2, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFjUamkg7jby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225d6d81-e374-4680-80c1-17a43b2060fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ],
      "source": [
        "m.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88uWT_-N7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794d6a97-64fa-4187-a57a-a105abdd0b68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 4.],\n",
              "        [5., 2.],\n",
              "        [3., 1.],\n",
              "        [7., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ],
      "source": [
        "# Transpose tensor m, which is essentially 2x4 to 4x2\n",
        "m.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfx8uRtl7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7834b469-871e-4687-eec9-d2123ed7ceaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 4.],\n",
              "        [5., 2.],\n",
              "        [3., 1.],\n",
              "        [7., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ],
      "source": [
        "# Same as\n",
        "m.transpose(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p2bHHeHJewn"
      },
      "source": [
        "## Broadcasting\n",
        "\n",
        "Two tensors are “broadcastable” if the following rules hold:\n",
        "\n",
        "*   Each tensor has at least one dimension.\n",
        "*   When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPyg44mxJeHP"
      },
      "outputs": [],
      "source": [
        "x=torch.empty(5,7,3)\n",
        "y=torch.empty(5,7,3)\n",
        "# x and y are broadcastable since all dimensions are equal\n",
        "\n",
        "x=torch.empty((0,))\n",
        "y=torch.empty(2,2)\n",
        "# x and y are not broadcastable, because x does not have at least 1 dimension\n",
        "\n",
        "x=torch.empty(5,3,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are broadcastable.\n",
        "# 1st trailing dimension: both have size 1\n",
        "# 2nd trailing dimension: y has size 1\n",
        "# 3rd trailing dimension: x size == y size\n",
        "# 4th trailing dimension: y dimension doesn't exist\n",
        "\n",
        "# but:\n",
        "x=torch.empty(5,2,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpudbDP9MI4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b075de58-4e06-45f5-9556-5c78002c55c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 3, 4, 1])\n",
            "torch.Size([3, 1, 7])\n"
          ]
        }
      ],
      "source": [
        "# How is the output dimension calculated?\n",
        "x=torch.empty(5,1,4,1)\n",
        "y=torch.empty(3,1,1)\n",
        "print((x+y).size())\n",
        "\n",
        "x=torch.empty(1)\n",
        "y=torch.empty(3,1,7)\n",
        "print((x+y).size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpCZhT8U7jbz"
      },
      "source": [
        "## Constructors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYn7XeYu7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71dd6b26-e39c-4140-9c8f-bf61753656fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 4., 5., 6., 7., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ],
      "source": [
        "# Create tensor from 3 to 8\n",
        "torch.arange(3., 8 + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH8X7Dts7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a35d512-6b24-4269-e0bb-ecc6a697b308"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 5.7000,  2.7000, -0.3000])"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ],
      "source": [
        "# Create tensor from 5.7 to -2.1 with step -3\n",
        "torch.arange(5.7, -2.1, -3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B14Dyrn7jbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116d9029-68b5-4cfe-c84e-c75ddc06b9be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.0000, 3.2632, 3.5263, 3.7895, 4.0526, 4.3158, 4.5789, 4.8421, 5.1053,\n",
              "         5.3684, 5.6316, 5.8947, 6.1579, 6.4211, 6.6842, 6.9474, 7.2105, 7.4737,\n",
              "         7.7368, 8.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ],
      "source": [
        "# returns a 1D tensor of equally spaced elements between start=3, end=8 and number of elements=20\n",
        "torch.linspace(3, 8, 20).view(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb4KEmjU7jb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec52589-9379-4daa-c4f7-dc823b53e20d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ],
      "source": [
        "# Create a tensor filled with 0's\n",
        "torch.zeros(3, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrOxrng27jb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e44973-8e33-451a-fd7d-79d64a10f0b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ],
      "source": [
        "# Create a tensor filled with 1's\n",
        "torch.ones(3, 2, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt6VUo1A7jb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8408dfe8-7769-44f2-9883-477107dd1c9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ],
      "source": [
        "# Create a tensor with the diagonal filled with 1\n",
        "torch.eye(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDCnuhOf7jb0"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81dgFtq67jb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "5e5a3915-1d53-447b-f4ba-bd3ce0a39381"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Numpy bridge!\n",
        "plt.hist(torch.randn(1000).numpy(), 100);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBhx09297jb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "a9a34075-2522-4b6c-b191-6f12207c538d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.hist(torch.randn(10**6).numpy(), 100);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyeN3wTV7jb1"
      },
      "source": [
        "## Casting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxMGbcNP7jb1"
      },
      "outputs": [],
      "source": [
        "# Helper to get what kind of tensor types\n",
        "torch.*Tensor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6pXTH4b7jb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b555ea44-d917-49f1-813d-7b87e80c0fa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ],
      "source": [
        "m = torch.Tensor([[2, 5, 3, 7],\n",
        "                  [4, 2, 1, 9]])\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TAG0hTN7jb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d3d31df-95ce-4364-e154-741abdf5234d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 5., 3., 7.],\n",
              "        [4., 2., 1., 9.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ],
      "source": [
        "# This is basically a 64 bit float tensor\n",
        "m_double = m.double()\n",
        "m_double"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFe9nMZi7jb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48d00da-9a10-4f35-c2cd-d09fa662c94b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 3, 7],\n",
              "        [4, 2, 1, 9]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ],
      "source": [
        "# This creates a tensor of type int8\n",
        "m_byte = m.byte()\n",
        "m_byte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSVzhX_I7jb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f84ed4-c1b1-44c4-b129-596a8232f61d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 5., 3., 7.],\n",
              "       [4., 2., 1., 9.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ],
      "source": [
        "# Converts tensor to numpy array\n",
        "m_np = m.numpy()\n",
        "m_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHfSv9BB7jb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cc59607-c234-4a71-c5dc-a77b98e28d80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.,  5.,  3.,  7.],\n",
              "       [ 4.,  2.,  1.,  9.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ],
      "source": [
        "# In-place fill of column 0 and row 0 with value -1\n",
        "m_np[0, 0] = -1\n",
        "m_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICAeMZLU7jb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6f5c88-680a-4483-8ce7-27cb198e8621"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.,  5.,  3.,  7.],\n",
              "        [ 4.,  2.,  1.,  9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CStd3ORV7jb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c0b143-e77d-4217-dca9-b9912d9a8501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4] tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor of integers ranging from 0 to 4\n",
        "import numpy as np\n",
        "n_np = np.arange(5)\n",
        "n = torch.from_numpy(n_np)\n",
        "print(n_np, n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gGi0E-h7jb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c2e73b-2c9a-48a1-f77d-c36880fbf619"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 4, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ],
      "source": [
        "# In-place multiplication of all elements by 2 for tensor n\n",
        "n.mul_(2)\n",
        "n_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yGGuawb7jb3"
      },
      "source": [
        "## Using the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3cSABmzDda2"
      },
      "outputs": [],
      "source": [
        "# If this cell fails you need to change the runtime of your colab notebook to GPU\n",
        "# Go to Runtime -> Change Runtime Type and select GPU\n",
        "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
        "\n",
        "# use the first gpu available if possible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rQvVYDMFIAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b25f5a76-9945-4490-93a0-0a49ced6168e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor's device: cpu\n",
            "tensor's device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Tensors can be moved between gpu and cpu memory\n",
        "\n",
        "tensor = torch.randn(5, 5) # create a 5x5 matrix filled with random numbers\n",
        "print(f\"tensor's device: {tensor.device}\") # by default tensors are stored in cpu memory (RAM)\n",
        "\n",
        "# Move your tensor to GPU device 0 if there is one (first GPU in the system)\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(device) # tensor.cuda() is an alternative although not recommended\n",
        "print(f\"tensor's device: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccZpZ5xzZ8Sy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "4a21b74c-4edf-4b02-c970-44dd2dbec74e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-264-7dcbcc2f788e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This throws an exception, since you can't operate on tensors stored in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# different devices, and the error message is pretty clear about that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "# A common mistake \n",
        "a = torch.randn(5, 2, device=device)\n",
        "b = torch.randn(1, 2)\n",
        "\n",
        "# This throws an exception, since you can't operate on tensors stored in\n",
        "# different devices, and the error message is pretty clear about that\n",
        "c = a * b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x59Bo0QnEUOU"
      },
      "source": [
        "# Gradient Computation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H25IsxuRKlry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db2b487-a5d9-41b5-f12a-20e5f34423dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of a with respecto to L: tensor([36., 81.])\n"
          ]
        }
      ],
      "source": [
        "# Tensors also track the operations applied on them in order to differentiate them\n",
        "\n",
        "# setting requires_grad to true tells the autograd engine that we want to compute\n",
        "# gradients for this tensor\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "\n",
        "L = 3*a**3\n",
        "L.sum().backward()\n",
        "print(f\"Gradient of a with respecto to L: {a.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnviODjmRdKC"
      },
      "source": [
        "Lets check if the computed gradients are correct:\n",
        "\n",
        "$\\frac{\\partial{L}}{\\partial{a}} = [9 * a_1^2, 9 * a_2^2]$\n",
        "\n",
        "$\\frac{\\partial{L}}{\\partial{a}} = [9 * 2^2, 9 * 3^2]$\n",
        "\n",
        "$\\frac{\\partial{L}}{\\partial{a}} = [36, 81]$\n",
        "\n",
        "As we can see the gradient vector matches the one computed by the autograd engine (no surprise there)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61qpDwtvU_E8",
        "outputId": "6008cbe8-b9af-42a6-ef3a-574356bb2f41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does a require gradients? : False\n",
            "Does b require gradients?: True\n"
          ]
        }
      ],
      "source": [
        "# Notice that the output tensor of an operation will require gradients even \n",
        "# if only a single input tensor has requires_grad=True.\n",
        "\n",
        "x = torch.rand(5, 5)\n",
        "y = torch.rand(5, 5)\n",
        "z = torch.rand((5, 5), requires_grad=True)\n",
        "\n",
        "a = x + y\n",
        "print(f\"Does a require gradients? : {a.requires_grad}\")\n",
        "b = x + z\n",
        "print(f\"Does b require gradients?: {b.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpQYoTsweeg-"
      },
      "source": [
        "Let's repeat with PyTorch one of the gradient calculations what we already did before outselves (with our own auto-differentiation engine):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "VgHLEcoFeeg_",
        "outputId": "c88874bc-6f54-4a84-9fc5-88524b38f5e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result = tensor(28., grad_fn=<MulBackward0>)\n",
            "The derivative of the result with respect to a is: tensor(11.)\n",
            "The derivative of the result with respect to b is: tensor(4.)\n",
            "The derivative of the result with respect to c is: tensor(4.)\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor(4.0, requires_grad = True)  # a = 4\n",
        "b = torch.tensor(3.0, requires_grad = True)  # b = 3\n",
        "c = a + b        # c = 4 + 3\n",
        "c.retain_grad()\n",
        "\n",
        "res = a * c      # res = a * c = 28\n",
        "\n",
        "print(\"Result =\", res)\n",
        "\n",
        "# Call backprop on the result\n",
        "res.backward()\n",
        "\n",
        "# Now all variables should contain in their \"grad\" the derivative d(res) / d(variable)\n",
        "print(\"The derivative of the result with respect to a is:\", a.grad)\n",
        "print(\"The derivative of the result with respect to b is:\", b.grad)\n",
        "# Also for intermediate results\n",
        "print(\"The derivative of the result with respect to c is:\", c.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-_70bB17jb4"
      },
      "source": [
        "## Much more\n",
        "\n",
        "There's definitely much more, but this was the basics about `Tensor`s fun.\n",
        "\n",
        "*Torch* full API can be found [here](https://pytorch.org/docs/stable/index.html).\n",
        "You'll find 100+ `Tensor` operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xl6U-RoEtY3"
      },
      "source": [
        "# Homework\n",
        "\n",
        "<font color=\"blue\">**Exercise 1:** The code below simulates a tiny neural network, however it throws an exception. As you build neural networks in PyTorch you will see this exception often. Look at the error message, explain whats happening and make the necessary changes to the code to get an output from this tiny network</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aGsG2MMGebg",
        "outputId": "8396bb25-528c-4292-dcc7-9dd922c09090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4490,  0.3699,  0.1368,  0.2974,  0.5646],\n",
            "        [-0.3858,  0.0381,  1.2865,  0.4263, -1.0048],\n",
            "        [-0.5296, -0.0190,  1.4845,  0.4485, -1.2751],\n",
            "        [ 1.3148,  0.7140, -1.0556,  0.1637,  2.1922],\n",
            "        [-1.1953, -0.2836,  2.4014,  0.5513, -2.5266]])\n",
            "torch.Size([5, 5]) torch.Size([1, 1])\n"
          ]
        }
      ],
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # Set the random seed so things are predictable\n",
        "\n",
        "# Features are 5 random normal variables\n",
        "features = torch.randn((1, 5))\n",
        "# True weights for our data, random normal variables again\n",
        "weights = torch.randn_like(features)\n",
        "# and a true bias term\n",
        "bias = torch.randn((1, 1))\n",
        "fts = torch.mm(features.t(), weights)\n",
        "print(fts + bias)\n",
        "print(fts.shape, bias.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This occurs because the matrix multiplication requires that the number of colums in the first matrix matches the number of rows on the second one, in order to be performed, since they have the same shape (1x5 and 1x5) by just changing the order of the second matrix to (5x1) --> (1x5 X 5x1) the rows and colums are matching, this can be done by doing the transpose of the second matrix with the function matrix.t()."
      ],
      "metadata": {
        "id": "C7laITSKJRuL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-bTQObReehE"
      },
      "source": [
        "<font color=\"blue\">**Exercise 2:** Once you manage to sucessfully run the code above notice how the shape of the tensors ```fts``` and ```bias``` are drastically different, yet they can be added together. Which internal PyTorch mechanism makes this addition happen?</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUuq1vffeehF"
      },
      "source": [
        "---\n",
        "\n",
        "Because broadcasting, since the bias shape is (1,1) and it can be done if:\n",
        "\n",
        "·Each tensor has at least one dimension.\n",
        "·When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8N-hhzmQZaA"
      },
      "source": [
        "# More Homework\n",
        "\n",
        "<font color=\"blue\">**Exercise 3:** Answer the following questions about the cell below</font>\n",
        "\n",
        "1. Does the value of ```t``` change? Why?\n",
        "2. Does the shape of ```t``` change? Why?\n",
        "3. Explain, in your own words. What is the stride of a tensor, why is it convenient to have them?\n",
        "4.  Pick a mathematical operation like cosine or square root (not those though 🙂). Can you find the correspoding function in the [torch library](https://https://pytorch.org/docs/stable/torch.html#pointwise-ops). \n",
        "5. Apply the function element-wise to ```a```.\n",
        "6. Is there a version of the function that operates in place? Does it return an error? Why? How can it be fixed?\n",
        "7. Run the same function on the GPU. Do you notice any difference in runtime? If not, why do you think that is?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__SC70eiXYn1",
        "outputId": "8c8b3163-7d4b-4ec3-dace-714dbb9afd72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  2,  4],\n",
              "        [ 6,  8, 10],\n",
              "        [12, 14, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ],
      "source": [
        "t = torch.tensor(list(range(9)))\n",
        "\n",
        "a = t.view(3, 3)\n",
        "a.mul_(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Yes, the value of t changes when a is modified because a is a view of t and it shares the same data storage as the original tensor.\n",
        "\n",
        "2.No, since a is created as a reshaped view of t.\n",
        "\n",
        "3.A set of numbers that tells you the number of elements in memory to go to a element of a determined dimension, it is useful for indexing and manipulation or the tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "rWEXaGvPPr7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4 and 5\n",
        "a.add(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJVeLpb1TvjZ",
        "outputId": "26efc144-e2df-4947-b350-94e76072e78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  3,  5],\n",
              "        [ 7,  9, 11],\n",
              "        [13, 15, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "a.add_(10000000000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO3GLx1FVyXl",
        "outputId": "4f105a31-bbaf-403b-f63b-0c0c6a1a625a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10000000000, 10000000002, 10000000004],\n",
              "        [10000000006, 10000000008, 10000000010],\n",
              "        [10000000012, 10000000014, 10000000016]])"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes but It does not return an error."
      ],
      "metadata": {
        "id": "ga4_NzFbVPtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "a = a.to('cuda')"
      ],
      "metadata": {
        "id": "nrJRf4MYW18F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.add_(10000000000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpi7zKFrW3mG",
        "outputId": "d8a5dfef-4b38-40d3-b24d-be00e93dc7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20000000000, 20000000002, 20000000004],\n",
              "        [20000000006, 20000000008, 20000000010],\n",
              "        [20000000012, 20000000014, 20000000016]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, I do not notice any change, probablly because the size of the tensor is too small, and with larger tensors the change should be more noticeable."
      ],
      "metadata": {
        "id": "Cikm9Bg2XZAa"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}